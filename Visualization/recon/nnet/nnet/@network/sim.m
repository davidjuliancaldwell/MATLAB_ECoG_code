function [Y,Xf,Af,E,perf]=sim(net,varargin)
%SIM Simulate a neural network.
%
%  SIM(NET,X) takes a network NET and inputs X and returns the outputs
%  Y generated by the network.  This syntax is equivalent to NET(X).
%
%  [Y,Xf,Af] = <a href="matlab:doc sim">sim</a>(NET,X,Xi,Ai) takes a dynamic network NET, inputs X,
%  and initial input and layer delays Xi and Ai.  It returns the outputs Y
%  and final input and layer delays states Xf and Af.
%
%  <a href="matlab:doc sim">sim</a> arguments can have two formats: matrices, for static
%  problems and networks with single inputs and outputs, and cell arrays
%  for multiple timesteps and networks with multiple inputs and outputs.
%
%  The matrix format is as follows:
%    X  - RxQ matrix
%    Y  - UxQ matrix.
%  Where:
%    Q  = number of samples
%    R  = number of elements in the network's input
%    U  = number of elements in the network's output
%
%  The cell array format is most general:
%    X  - NixTS cell array, each element X{i,ts} is an RixQ matrix.
%    Xi - NixID cell array, each element Xi{i,k} is an RixQ matrix.
%    Ai - NlxLD cell array, each element Ai{i,k} is an SixQ matrix.
%    Y  - NOxTS cell array, each element Y{i,ts} is a UixQ matrix.
%    Xf - NixID cell array, each element Xf{i,k} is an RixQ matrix.
%    Af - NlxLD cell array, each element Af{i,k} is an SixQ matrix.
%  Where:
%    TS = number of time steps
%    Ni = NET.<a href="matlab:doc nnproperty.net_numInputs">numInputs</a>
%    Nl = NET.<a href="matlab:doc nnproperty.net_numLayers">numLayers</a>, 
%    No = NET.<a href="matlab:doc nnproperty.net_numOutputs">numOutputs</a>
%    ID = NET.<a href="matlab:doc nnproperty.net_numInputDelays">numInputDelays</a>
%    LD = NET.<a href="matlab:doc nnproperty.net_numLayerDelays">numLayerDelays</a>
%    Ri = NET.<a href="matlab:doc nnproperty.net_inputs">inputs</a>{i}.<a href="matlab:doc nnproperty.input_size">size</a>
%    Si = NET.<a href="matlab:doc nnproperty.net_layers">layers</a>{i}.<a href="matlab:doc nnproperty.layer_size">size</a>
%    Ui = NET.<a href="matlab:doc nnproperty.net_outputs">outputs</a>{i}.<a href="matlab:doc nnproperty.output_size">size</a>
%
%  The columns of Xi, Xf, Ai, and Af are ordered from oldest delay
%  condition to most recent:
%    Xi{i,k} = input i at time ts=k-ID.
%    Xf{i,k} = input i at time ts=TS+k-ID.
%    Ai{i,k} = layer output i at time ts=k-LD.
%    Af{i,k} = layer output i at time ts=TS+k-LD.
%
%  [Y,Pf,Af] = SIM(net,{Q TS},Pi,Ai) is used for networks
%  which do not have an input, such as Hopfield networks
%  when cell array notation is used.
%
%  Here a static feedforward network is created, trained on some data, then
%  simulated using SIM and network notation.
%
%    [x,t] = <a href="matlab:doc simplefit_dataset">simplefit_dataset</a>;
%    net = <a href="matlab:doc feedforwardnet">feedforwardnet</a>(10);
%    net = <a href="matlab:doc train">train</a>(net,x,t);
%    y1 = <a href="matlab:doc sim">sim</a>(net,x)
%    y2 = net(x)
%
%  Here a dynamic NARX network is created, trained, and simulated on
%  time series data.
%
%   [X,T] = <a href="matlab:doc simplenarx_dataset">simplenarx_dataset</a>;
%   net = <a href="matlab:doc narxnet">narxnet</a>(1:2,1:2,10);
%   <a href="matlab:doc view">view</a>(net)
%   [Xs,Xi,Ai,Ts] = <a href="matlab:doc preparets">preparets</a>(net,X,{},T);
%   net = <a href="matlab:doc train">train</a>(net,Xs,Ts,Xi,Ai);
%   Y1 = <a href="matlab:doc sim">sim</a>(net,Xs,Xi,Ai)
%   Y2 = net(Xs,Xi,Ai)
%
%  Simulation with Parallel Computing:
%
%  Parallel Computing Toolbox allows Neural Network Toolbox to simulate
%  networks faster and on larger datasets than can fit on one PC.
%
%  Here simulation automatically happens across MATLAB workers.
%
%    matlabpool open
%    [X,T] = vinyl_dataset;
%    net = feedforwardnet(10);
%    net = train(net,X,T,'useParallel','yes','showResources','yes');
%    Y = net(X,'useParallel','yes');
%
%  Use Composite values to distribute the data manually, and get back
%  the results as a Composite value.  If the data is loaded as it is
%  distributed then while each peice of the dataset must fit in RAM, the
%  entire dataset is only limited by the number of workers RAM.
%
%    Xc = Composite;
%    for i=1:numel(Xc)
%      Xc{i} = X + rand(size(X))*0.1; % (Use real data instead of random)
%    end
%    Yc = net(Xc);
%
%  Networks can be simulated using the current GPU device, if it is
%  supported by the Parallel Computing Toolbox.
%
%    Y = net(X,'useGPU','yes','showResources','yes');
%
%  To put the data on a GPU manually, and get the results on the GPU:
%
%    [Xgpu,Q] = <a href="matlab:doc nndata2gpu">nndata2gpu</a>(X);
%    Ygpu = net(Xgpu);
%    Y = <a href="matlab:doc gpu2nndata">gpu2nndata</a>(Ygpu,Q);
%
%  To run in parallel, with workers associated with unique GPUs taking
%  advantage of that hardware, while the rest of the workers use CPUs:
%
%    Y = net(X,'useParallel','yes','useGPU','yes','showResources','yes');
%
%  Only using workers with unique GPUs may result in higher speed, as CPU
%  workers may not keep up.
%
%    Y = net(X,'useParallel','yes','useGPU','only','showResources','yes');
%
%  Or manually distribute data as a Composite, choosing the size of each
%  subset of data to match whether each worker has a GPU or not.  For
%  instance, if only the first two workers have unique GPUs:
%
%    Xc = Composite;
%    for i=1:numel(Xc)
%      Xc{i} = X + rand(size(X))*0.1; % (Use real data instead of random)
%    end
%    spmd
%      if labindex <=2, [Xc,Q] = <a href="matlab:doc nndata2gpu">nndata2gpu</a>(Xc); end
%    end
%    Yc = net(Xc,'showResources','yes');
%    spmd
%      if labindex <=2, Yc = <a href="matlab:doc gpu2nndata">gpu2nndata</a>(Yc,Q); end
%    end
%
%  Defining Composite values as above can also let you balance each subset
%  of data for GPUs with differing speeds and memory.
%
%  See also INIT, REVERT, ADAPT, TRAIN

% Copyright 1992-2012 The MathWorks, Inc.
% $Revision: 1.8.4.18.2.1 $ $Date: 2012/07/28 23:34:27 $

% CHECK AND FORMAT ARGUMENTS
% --------------------------

% Network
if nargin < 1, error(message('nnet:Args:NotEnough')); end
if ~isa(net,'network')
  error('nnet:train:arguments','First argument is not a neural network.');
end
net = struct(net);
net.trainFcn = ''; % Disable training related setup
[~,zeroDelayLoop] = nn.layer_order(net);
 if zeroDelayLoop, error(message('nnet:NNet:ZeroDelayLoop')); end

% Calculation Mode
if ~isempty(varargin) && isstruct(varargin{end}) && isfield(varargin{end},'name')
  if isdeployed
    calcMode = nnMATLAB;
  else
    calcMode = nncalc.defaultMode(net,varargin{end}); 
  end
  varargin(end) = [];
else
  n = numel(varargin);
  i = n + 1;
  while (i-2 > 0) && ischar(varargin{i-2})
    i = i - 2;
  end
  if (i < n)
    nameValuePairs = varargin(i:n);
    varargin(i:n) = [];
    if isdeployed
      calcMode = nnMATLAB;
    else
      [calcMode,err] = nncalc.options2Mode(net,nameValuePairs);
      if ~isempty(err), error('nnet:train:calcMode',err); end
    end
  elseif isdeployed
    calcMode = nnMATLAB;
  else
    calcMode = nncalc.defaultMode(net);
  end
end
problem = calcMode.netCheck(net,calcMode.hints,false,false);
if ~isempty(problem), error(problem); end

% Check Composite Data for consistency
nargs = numel(varargin);
if nargs >= 1
  isComposite = isa(varargin{1},'Composite');
else
  isComposite = false;
end
for i=2:nargs
  if isComposite ~= isa(varargin{i},'Composite')
    error('nnet:sim:Composite','Data values must be all Composite or not.');
  end
end

% Check gpuArray data for consistency
if nargs >= 1
  isGPUArray = isa(varargin{1},'parallel.gpu.GPUArray');
else
  isGPUArray = false;
end
for i=2:nargs
  vi = varargin{i};
  if ~isempty(vi) && (isGPUArray ~= isa(vi,'parallel.gpu.GPUArray')) 
    error('nnet:sim:Composite','Data values must be all gpuArray or not.');
  end
end

% Fill in missing data consistent with type
if isComposite
  emptyCell = Composite;
  oneCell = Composite;
  for i=1:numel(emptyCell)
    emptyCell{i} = {};
    oneCell{i} = {1};
  end
else
  emptyCell = {};
  oneCell = {1};
end
if (nargs < 1), X = emptyCell; else X = varargin{1}; end
if (nargs < 2), Xi = emptyCell; else Xi = varargin{2}; end
if (nargs < 3), Ai = emptyCell; else Ai = varargin{3}; end
if (nargs < 4), T = emptyCell; else T = varargin{4}; end
if (nargs < 5) || isempty(varargin{5}), EW=oneCell; else EW=varargin{5}; end
if isComposite
  for i=1:numel(X)
    if ~exist(X,i), X{i} = {}; end
    if ~exist(T,i), T{i} = {}; end
    if ~exist(Xi,i), Xi{i} = {}; end
    if ~exist(Ai,i), Ai{i} = {}; end
    if ~exist(EW,i), EW{i} = {1}; end
  end
end
% X a Matrix or Cell? Use to format Y later.
if isComposite
  spmd, xMatrix = ~iscell(X) && ~isa(X,'parallel.gpu.GPUArray'); end
elseif isGPUArray
  xMatrix = false;
else
  xMatrix = ~iscell(X);
end

% Convert explicit timesteps to inputs
if ~isComposite && ~isGPUArray
  xMatrix = ~iscell(X);
  if (net.numInputs == 0)
    if xMatrix && isscalar(X)
      % Q
      X = {zeros(0,X)};
    elseif ~xMatrix && isscalar(X) && isscalar(X{1})
      % {TS}
      X = cell(1,X{1});
    elseif xMatrix && (ndims(X)==2) && all(size(X)==[1 2])
      % [Q TS]
      Q = X(1);
      TS = X(2);
      X = cell(1,TS);
      for i=1:TS,X{i} = zeros(1,Q); end
      xMatrix = false;
    elseif ~xMatrix && (ndims(X)==2) && all(size(X)==[1 2]) ...
        && isscalar(X{1}) && isscalar(X{2})
      % {Q TS}
      Q = X{1}; TS = X{2};
      X = cell(1,TS);
      for i=1:TS,X{i} = zeros(1,Q); end
      xMatrix = false;
    end
  end
  X = nntype.data('format',X,'Inputs');
end

% NNET 5.1 Backward Compatibility
if ~isComposite
  tMatrix = ~iscell(T);
  if ~isempty(T), T = nntype.data('format',T,'Targets'); end
end

% SIMULATE NETWORK
% ----------------

if isComposite
  spmd
    [data,err] = simData(net,X,Xi,Ai,T,EW);
    if ~isempty(err), nnerr.throw(err), end
  end
else
  [data,err] = simData(net,X,Xi,Ai,T,EW);
  if ~isempty(err), nnerr.throw(err), end
end

[calcMode,calcNet,calcData,calcHints,~,resourceText] = nncalc.setup1(calcMode,net,data);
if ~isempty(resourceText)
  disp(' ')
  disp('Computing Resources:')
  nntext.disp(resourceText)
  disp(' ')
end

isParallel = isa(calcMode,'Composite');
numOutputArgs = nargout;
if isParallel
  spmd
    [calcLib,calcNet] = nncalc.setup2(calcMode,calcNet,calcData,calcHints,isParallel);
    ws = warning('off','parallel:gpu:kernel:NullPointer');
    if numOutputArgs >= 3
      [Y,Af] = calcLib.y(calcNet);
    else
      Y = calcLib.y(calcNet);
    end
    warning(ws);
    if isComposite
      if numOutputArgs >= 2, Xf = getXf(net,data); end
      if (xMatrix)
        if isempty(Y), Y = zeros(sum(nn.output_sizes(net)),data.Q); else Y = cell2mat(Y); end
      end
    end
    if (labindex == 1), mainWorkerInd = calcLib.mainWorkerInd; end
  end
  if ~isComposite
    mainWorkerInd = mainWorkerInd{1};
    Y = Y{mainWorkerInd};
    if xMatrix
      if isempty(Y), Y = zeros(sum(nn.output_sizes(net)),data.Q); else Y = cell2mat(Y); end
    end
    if nargout >= 2, Xf = getXf(net,data); end
    if nargout >= 3, Af = Af{mainWorkerInd}; end
  end
else
  [calcLib,calcNet] = nncalc.setup2(calcMode,calcNet,calcData,calcHints,isParallel);
  ws = warning('off','parallel:gpu:kernel:NullPointer');
  if nargout >= 3
    [Y,Af] = calcLib.y(calcNet);
  else
    Y = calcLib.y(calcNet);
  end
  warning(ws);
  if nargout >= 2, Xf = getXf(net,data); end
  if (xMatrix)
    if isempty(Y), Y = zeros(sum(nn.output_sizes(net)),data.Q); else Y = cell2mat(Y); end
  end
end

% NNET 5.1 Backward Compatibility
if ~isComposite
  if nargout >= 4
    E = gsubtract(data.T,Y);
    if (nargout>4) && (tMatrix)
      if (TS==0) || (net.numOutputs == 0)
        E = zeros(sum(nn.output_sizes),Q);
      else
        E = cell2mat(E);
      end
    end
  end
  if nargout >= 5
    perf = feval(net.performFcn,net,data.T,Y,data.EW,net.performParam);
  end
end

function [data,err] = simData(net,X,Xi,Ai,T,EW)

err = '';

if ~isa(X,'parallel.gpu.GPUArray')
  if ~isempty(X), X = nntype.data('format',X,'Inputs'); end
  if ~isempty(Xi), Xi = nntype.data('format',Xi,'Input delay states'); end
  if ~isempty(Ai), Ai = nntype.data('format',Ai,'Layer delay states'); end

  % Q
  if ~isempty(X) && (size(X{1},2) > 0)
    Q = size(X{1},2);
  elseif ~isempty(Xi) && ~isempty(Xi{1})
    Q = size(Xi{1},2);
  elseif ~isempty(Ai) && ~isempty(Ai{1})
    Q = size(Ai{1},2);
  else
    Q = 0;
  end

  % TS
  if (net.numInputs == 0) && (size(X,1) == 1) && (size(X{1},1)==0)
    TS = size(X,2);
    X = cell(0,TS);
  elseif size(X,2) > 0
    TS = size(X,2);
  else
    TS = 0;
  end

  % Input
  if isempty(X) || (net.numInputs == 0)
    X = cell(net.numInputs,TS);
    for i=1:net.numInputs
      for ts=1:TS
        X{i,ts} = zeros(net.inputs{i}.size,Q);
      end
    end
  end
  err = nntype.data('check',X);
  if ~isempty(err), err = ['Inputs: ' err]; return; end
  [Xn,Xq,Xts,Xs] = nnfast.nnsize(X);
  if isempty(X), Xq = Q; end
  if (Xs == 1) && (net.numInputs ~= 1)
    Nn = zeros(1,net.numInputs);
    for i=1:net.numInputs,Nn(i) = net.inputs{i}.size; end
    if (Xn == sum(Nn))
      X2 = cell(net.numInputs,Xts);
      for ts=1:Xts
        X2(:,ts) = mat2cell(X{1,ts},Nn,Xq);
      end
      X = X2;
      Xn = Nn;
      Xs = net.numInputs;
    end
  end
  if (Xs ~= net.numInputs)
    err = 'Number of inputs does not match net.numInputs.'; return;
  end

  % Target
  if isempty(T)
    targetIndices = find(net.outputConnect);
    T = cell(net.numOutputs,Xts);
    for i=1:net.numOutputs
      ii = targetIndices(i);
      ti = NaN(net.outputs{ii}.size,Xq);
      for j=1:Xts, T{i,j} = ti; end
    end
  end
  err = nntype.data('check',T);
  if ~isempty(err), err = ['Targets: ' err]; return; end
  [Tn,Tq,Tts,Ts] = nnfast.nnsize(T);
  if ((Ts == 0) || (Tts ==0)) && (Tq == 0)
    Tq = Xq;
  end
  if (Tq ~= Xq)
    err = 'Inputs and targets have different numbers of samples.'; return
  end
  if (Tts ~= Xts)
    err = 'Inputs and targets have different numbers of timesteps.'; return
  end
  if (Ts == 1) && (net.numOutputs ~= 1)
    Nn = zeros(1,net.numOutputs);
    outputInd = find(net.outputConnect);
    for i=1:net.numOutputs,Nn(i) = net.outputs{outputInd(i)}.size; end
    if (Tn == sum(Nn))
      T2 = cell(net.numOutputs,Xts);
      for ts=1:Xts
        T2(:,ts) = mat2cell(T{1,ts},Nn,Tq);
      end
      T = T2;
      Tn = Nn;
      Ts = net.numOutputs;
    end
  end
  if (Ts ~= net.numOutputs)
    err = 'Number of targets does not match net.numOutputs.'; return;
  end

  % Input States
  if isempty(Xi)
    Xi = cell(net.numInputs,net.numInputDelays);
    for i=1:net.numInputs
      xi = zeros(net.inputs{i}.size,Xq);
      for j=1:net.numInputDelays, Xi{i,j} = xi; end
    end
  end
  err = nntype.data('check',Xi);
  if ~isempty(err), err = ['Input states: ' err]; return; end
  [Xin,Xiq,Xits,Xis] = nnfast.nnsize(Xi);
  if ((Xis == 0) || (Xits ==0)) && (Xiq == 0)
    Xiq = Xq;
  end
  if (Xiq ~= Xq)
    err = 'Inputs and input states have different numbers of samples.'; return
  end
  if (Xis ~= net.numInputs)
    err = 'Number of input states does not match net.numInputs.'; return;
  end
  if (Xits ~= net.numInputDelays)
    err = 'Number of input state timesteps does not match net.numInputDelays.'; return
  end
  if (Xis > 0) && (Xits > 0)
    for i=1:Xis
      if Xin(i) ~= net.inputs{i}.size
        err = 'Input state sizes does not match net.inputs{:}.size.'; return;
      end
    end
  end

  % Layer States
  if isempty(Ai)
    Ai = cell(net.numLayers,net.numLayerDelays);
    for i=1:net.numLayers
      ai = zeros(net.layers{i}.size,Xq);
      for j=1:net.numLayerDelays, Ai{i,j} = ai; end
    end
  end
  err = nntype.data('check',Ai);
  if ~isempty(err), err = ['Layer states: ' err]; return; end
  [Ain,Aiq,Aits,Ais] = nnfast.nnsize(Ai);
  if ((Ais == 0) || (Aits ==0)) && (Aiq == 0)
    Aiq = Xq;
  end
  if (Aiq ~= Xq)
    err = 'Inputs and layer states have different numbers of samples.'; return
  end
  if (Ais ~= net.numLayers)
    err = 'Number of layers states does not match net.numLayers.'; return;
  end
  if (Aits ~= net.numLayerDelays)
    err = 'Number of layer state timesteps does not match net.numLayerDelays.'; return
  end

else
  % Infer Precision
  if ~isempty(X)
    precision = class(gather(X(1)));
  elseif ~isempty(Xi)
    precision = class(gather(Xi(1)));
  elseif ~isempty(Ai)
    precision = class(gather(Ai(1)));
  else
    precision = 'double';
  end

  % QQ
  QQs = [size(X,1) size(Xi,1) size(Ai,1)];
  QQs(QQs == 0) = [];
  QQ = max([0 QQs]);
  if any(QQs ~= QQ)
    err = 'Number of samples (rows of gpuArrays) of data arguments do not match.';
    return
  end

  % Q
  if ~isempty(X)
    Qv = X;
  elseif ~isempty(Xi)
    Qv = Xi;
  elseif ~isempty(Ai)
    Qv = Ai;
  else
    Qv = [];
  end
  realRows = gather(any(isfinite(Qv),2));
  Q = find(realRows,1,'last');
  
  % Network dimensions
  Ni = sum(nn.input_sizes(net));
  Nl = sum(nn.layer_sizes(net));
  NID = net.numInputDelays;
  NLD = net.numLayerDelays;
  anyInputsZero = any(nn.input_sizes(net)==0);

  % Infer TS
  Ni_TS = size(X,2);
  if (Ni_TS == 0) && (Nl_TS == 0)
    TS = 0;
  elseif (Ni > 0)
    TS = Ni_TS / Ni;
    if (TS ~= floor(TS))
      if anyInputsZero
        err = 'Input data size  (gpuArray columns) does not match input sizes. Fix data or CONFIGURE network.';
      else
        err = 'Input data size  (gpuArray columns) does not match input sizes.';
      end
      return;
    end
  else
    TS = 0;
  end

  % Expand empty values
  if isempty(X), X = gpuArray(nan(QQ,Ni*TS,precision)); end
  if isempty(Xi), Xi = gpuArray(nan(QQ,Ni*NID,precision)); end
  if isempty(Ai), Ai = gpuArray(nan(QQ,Nl*NLD,precision)); end

  % Check sizes
  if any(size(X) ~= [QQ Ni*TS])
    if anyInputsZero
      err = 'Input data size  (gpuArray columns) does not match input sizes. Fix data or CONFIGURE network.';
    else
      err = 'Input data size  (gpuArray columns) does not match input sizes.';
    end
    return
  end
  if any(size(Xi) ~= [QQ Ni*NID])
    err = 'Input state size  (gpuArray columns) does not match input sizes times input delay states.';
  end
  if any(size(Ai) ~= [QQ Nl*NLD])
    err = 'Layer state size  (gpuArray columns) does not match layers sizes times layer delay states.';
  end
  
  T = {};
  EW = {};
end

data = struct;
data.X = X;
data.Xi = Xi;
data.Ai = Ai;
data.Q = Q;
data.TS = TS;

% NNET 5.1 Compatibility
data.T = T;
data.EW = EW;


function Xf = getXf(net,data)

if ~isempty(data)
  Xf = cell(net.numInputs,net.numInputDelays);
  for ts=1:net.numInputDelays
    x_ts = ts+data.TS-net.numInputDelays;
    if (x_ts) < 1
      xi_ts = x_ts + net.numInputDelays;
      Xf(:,ts) = data.Xi(:,xi_ts);
    else
      Xf(:,ts) = data.X(:,x_ts);
    end
  end
else
  Xf = [];
end

